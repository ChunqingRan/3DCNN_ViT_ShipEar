import torch
import torch.nn as nn
import os
import warnings
from config import cfg


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""

    def __init__(self, patience=None, delta=None, monitor=None, mode=None, save_path=None):
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™å°è¯•ä»cfgè¯»å–ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
        self.patience = patience or getattr(cfg, 'patience', 15)
        self.min_delta = delta or getattr(cfg, 'min_delta', 0.0)
        self.monitor = monitor or getattr(cfg, 'monitor', 'val_acc')  # é»˜è®¤ç›‘æ§å‡†ç¡®ç‡
        self.mode = mode or getattr(cfg, 'early_stop_mode', 'max')  # accæ˜¯max, lossæ˜¯min

        # ç¡®å®šä¿å­˜è·¯å¾„
        if save_path:
            self.save_path = save_path
        elif hasattr(cfg, 'save_dir'):
            self.save_path = os.path.join(cfg.save_dir, "best_model.pth")
        else:
            self.save_path = "best_model.pth"

        self.verbose = True
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_epoch = 0

    def __call__(self, current_score, model, epoch):
        # åˆå§‹åŒ–
        if self.best_score is None:
            self.best_score = current_score
            self._save_best_model(model, epoch)
            return

        # åˆ¤æ–­æ˜¯å¦æ”¹è¿›
        if self.mode == "min":
            improved = current_score < (self.best_score - self.min_delta)
        else:  # max
            improved = current_score > (self.best_score + self.min_delta)

        if improved:
            self.best_score = current_score
            self.counter = 0
            self.best_epoch = epoch
            self._save_best_model(model, epoch)
            if self.verbose:
                print(f"âœ… ç›‘æ§æŒ‡æ ‡æ”¹è¿› ({self.monitor}): {current_score:.6f} â†’ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆEpoch {epoch}ï¼‰")
        else:
            self.counter += 1
            if self.verbose:
                print(
                    f"âš ï¸ æ—©åœè®¡æ•°å™¨: {self.counter}/{self.patience} (å½“å‰{self.monitor}: {current_score:.6f}, æœ€ä½³: {self.best_score:.6f})")
            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼æœ€ä½³Epoch: {self.best_epoch}, æœ€ä½³{self.monitor}: {self.best_score:.6f}")

    def _save_best_model(self, model, epoch):
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        directory = os.path.dirname(self.save_path)
        if directory and not os.path.exists(directory):
            os.makedirs(directory)

        # å¤„ç† DataParallel
        if isinstance(model, nn.DataParallel):
            model_state = model.module.state_dict()
        else:
            model_state = model.state_dict()

        save_dict = {
            "epoch": epoch,
            "model_state_dict": model_state,
            "best_score": self.best_score,
            # å®‰å…¨åœ°ä¿å­˜ config (è¿‡æ»¤æ‰ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡)
            "config": {k: str(v) for k, v in cfg.__dict__.items() if not k.startswith("__")}
        }

        torch.save(save_dict, self.save_path)
        if self.verbose:
            print(f"ğŸ“Œ æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {self.save_path}")

    def load_best_model(self, model):
        if os.path.exists(self.save_path):
            checkpoint = torch.load(self.save_path, map_location=cfg.device)

            # å¤„ç† state_dict é”®åå¯èƒ½å¸¦ module. å‰ç¼€çš„é—®é¢˜
            state_dict = checkpoint["model_state_dict"]
            new_state_dict = {}
            for k, v in state_dict.items():
                if k.startswith('module.'):
                    new_state_dict[k[7:]] = v
                else:
                    new_state_dict[k] = v

            model.load_state_dict(new_state_dict, strict=False)
            if self.verbose:
                print(f"ğŸ“¥ åŠ è½½æœ€ä½³æ¨¡å‹ï¼ˆEpoch {checkpoint['epoch']}, {self.monitor}: {checkpoint['best_score']:.6f}ï¼‰")
            return model
        else:
            raise FileNotFoundError(f"æœ€ä½³æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.save_path}")


def build_optimizer_and_scheduler(model):
    """æ„å»ºä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    # å°è¯•è·å–åˆ†å±‚å­¦ä¹ ç‡å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰å®ç°æ¥å£åˆ™è·å–é»˜è®¤å‚æ•°
    if hasattr(model, "get_learning_rates"):
        params = model.get_learning_rates()
    elif hasattr(model, "module") and hasattr(model.module, "get_learning_rates"):
        params = model.module.get_learning_rates()
    else:
        warnings.warn("æ¨¡å‹æœªå®ç° get_learning_rates æ¥å£ï¼Œä½¿ç”¨ç»Ÿä¸€å­¦ä¹ ç‡")
        params = model.parameters()

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        params,
        lr=cfg.lr if hasattr(cfg, 'lr') else 1e-4,
        weight_decay=cfg.weight_decay if hasattr(cfg, 'weight_decay') else 1e-4,
        betas=(0.9, 0.999)
    )

    # è°ƒåº¦å™¨ (é»˜è®¤ä½¿ç”¨ CosineAnnealingLR)
    scheduler_type = getattr(cfg, 'scheduler_type', 'CosineAnnealingLR')
    max_epochs = getattr(cfg, 'epochs', 50)  # æ³¨æ„ä¹‹å‰æ˜¯ max_epochsï¼Œæ–°configæ˜¯ epochs
    min_lr = getattr(cfg, 'min_lr', 1e-6)

    if scheduler_type == "ReduceLROnPlateau":
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode="min",  # æ³¨æ„ï¼šå¦‚æœæ˜¯ç›‘æ§å‡†ç¡®ç‡ï¼Œè¿™é‡Œå¯èƒ½æ˜¯ max
            factor=0.5,
            patience=5,
            min_lr=min_lr,
            verbose=True
        )
    elif scheduler_type == "CosineAnnealingLR":
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=max_epochs,
            eta_min=min_lr,
            # verbose=True # Pytorch æ—§ç‰ˆæœ¬å¯èƒ½ä¸æ”¯æŒ verbose
        )
    elif scheduler_type == "StepLR":
        scheduler = torch.optim.lr_scheduler.StepLR(
            optimizer,
            step_size=10,
            gamma=0.7,
            verbose=True
        )
    else:
        scheduler = None

    return optimizer, scheduler